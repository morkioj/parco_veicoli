{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljMTBuD5QFXb"
      },
      "source": [
        "# DATA COLLECTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozVlaS8-V3mA"
      },
      "source": [
        "Installazione librerie necessarie\n",
        "odfpy: gestione in python degli opendocument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "9stKdRadV3Wi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting odfpyNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Giovanni\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading odfpy-1.4.1.tar.gz (717 kB)\n",
            "     -------------------------------------- 717.0/717.0 KB 4.1 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting defusedxml\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Using legacy 'setup.py install' for odfpy, since package 'wheel' is not installed.\n",
            "Installing collected packages: defusedxml, odfpy\n",
            "  Running setup.py install for odfpy: started\n",
            "  Running setup.py install for odfpy: finished with status 'done'\n",
            "Successfully installed defusedxml-0.7.1 odfpy-1.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install odfpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQyYtcI4R_Ua"
      },
      "source": [
        "Importazione librerie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6TeRlmeS2vu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3SwE6CefGg-"
      },
      "source": [
        "Recupero i dataset dal progetto github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8JXQXP2eeMcG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'parco_veicoli'...\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/morkioj/parco_veicoli.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck2Z_FI-S64m"
      },
      "source": [
        "**Importazione files ods**\n",
        "* Per ogni file presente nella cartella estraggo il contenuto del foglio \"AV per regione\" e da questo genero un dataframe pandas\n",
        "* A questo df, aggiungo la colonna 'Anno' estrando il valore dal nome del file\n",
        "* Inserisco il df in una lista di df\n",
        "* Iterati tutti i file nella cartella, unisco tutti i df presenti nella lista in un nuovo dataframe (df_orig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFWKLlAQ_Awb"
      },
      "outputs": [],
      "source": [
        "#drive.mount('/content/drive')\n",
        "#folder_path=\"/content/drive/MyDrive/Colab Notebooks/dataset/circolante\"\n",
        "folder_path=\"/content/parco_veicoli/dataset/parco_veicoli_circolante/\"\n",
        "file_path=\"\"\n",
        "sheet_name=\"AV_per_regione\"\n",
        "sheet_name2=\"AV per regione\"\n",
        "df_list=[]\n",
        "\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "for file_name in file_list:\n",
        "  file_path = os.path.join(folder_path,file_name)\n",
        "  #Ottengo lo stream binario (rb: read binary) del contenuto del file per passarlo come parametro a pd.read\n",
        "  with open(file_path, 'rb') as f:\n",
        "    file_content = f.read()\n",
        "  file_stream=BytesIO(file_content)\n",
        "  # Per compatibilità con la recente versione di pandas, anzichè passargli il percorso, gli passo il file_stream\n",
        "    # engine='odf' -> foglio di calcolo openoffice\n",
        "    # header=1 -> salta la prima riga ed utilizza la seconda come intestazione colonne\n",
        "  # Utilizzo il try-except perche alcuni file hanno il foglio con _ nel nome mentre altri hanno lo spazio\n",
        "  try:\n",
        "    df_file =pd.read_excel(io=file_stream,sheet_name=sheet_name,engine='odf',header=1)\n",
        "  except ValueError:\n",
        "    df_file =pd.read_excel(io=file_stream,sheet_name=sheet_name2,engine='odf',header=1)\n",
        "\n",
        "  #estraggo l'anno dal nome del file e lo inserisco in una nuova colonna\n",
        "  df_file['ANNO'] = int(file_name.split('_')[-1].replace('.ods',''))\n",
        "\n",
        "  #Inserisco in dataframe nella lista\n",
        "  df_list.append(df_file)\n",
        "  print(f\"{file_name} importato...\")\n",
        "\n",
        "#Una volta ottenuti tutti i dataframe (uno per ogni file) ed inseriti nella lista, li concateno tutti in una nuova lista\n",
        "df_orig = pd.concat(df_list, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj0tAI7HBtqn"
      },
      "source": [
        "# DATA CLEANING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va7uPB3aPbN-"
      },
      "source": [
        "**PRIMA PARTE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02xQPXCYySOY"
      },
      "source": [
        "1.   Sostituisco i campi nulli delle colonne 'Regione' e 'Alimentazione' con il valore contenuto nel record precedente\n",
        "2.   Sostituisco i campi nulli delle colonne numeriche con 0\n",
        "3.   Converto i float in int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfgRi_udWdEO"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_opt=df_orig.copy()\n",
        "#1\n",
        "df_opt['REGIONE']=df_opt['REGIONE'].ffill()\n",
        "df_opt['ALIMENTAZIONE']=df_opt['ALIMENTAZIONE'].ffill()\n",
        "#2\n",
        "columns_to_fill = ['EURO 0', 'EURO 1', 'EURO 2', 'EURO 3', 'EURO 4', 'EURO 5', 'EURO 6', 'Non contemplato', 'Non identificato']\n",
        "df_opt[columns_to_fill] = df_opt[columns_to_fill].replace({pd.NA: 0, np.nan: 0})\n",
        "\n",
        "#3\n",
        "# df.select_dtypes(include=['float'] ottengo tutte le colonne di tipo float\n",
        "# .colums e ne prendo i nomi\n",
        "# {col: 'int' for col in ...} dictionary comprehension: crea un dizionario dove le chiavi sono i nomi delle colonne ed i valori 'int'\n",
        "# quindi per ogni colonna float del df crea una coppia del dizionario nella forma <nomecolonna;'int'>\n",
        "df_opt = df_opt.astype({col: 'int' for col in df_opt.select_dtypes(include=['float']).columns})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVziGcxa0vFL"
      },
      "source": [
        "4. Rimuovo i subtotali regionali (Campo Regione contiene 'Totale')\n",
        "5. Rimuovo la suddivisione per fascia di cilindrata (Campo Alimentazione non contiene 'Totale')\n",
        "6. Rimuovo la colonna 'FASCIA' in conseguenza del punto 4\n",
        "7. Rimuovo la parola 'Totale' dalla descrizione delle alimentazioni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA9X4b2K02RM"
      },
      "outputs": [],
      "source": [
        "# Ricerca di testo all'interno del campo (case insensitive e nan da considerarsi false)\n",
        "# 4\n",
        "df_filt = df_opt[~df_opt['REGIONE'].str.contains('totale', case=False, na=False)]\n",
        "#5\n",
        "df_filt = df_filt[df_filt['ALIMENTAZIONE'].str.contains('totale', case=False, na=False)].reset_index(drop=True)\n",
        "#6\n",
        "df_filt=df_filt.drop(columns=['FASCIA'],axis=1)\n",
        "#7\n",
        "df_filt['ALIMENTAZIONE']=df_filt['ALIMENTAZIONE'].str.replace(\" totale\",\"\",case=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_u0MjIV2uus"
      },
      "source": [
        "**SECONDA PARTE**\n",
        "\n",
        "1. Assimilo i veicoli senza classe di inquinamento nella EURO 0 ([NON IDENTIFICATO]==0 --> EURO 0)\n",
        "2. Sposto i veicoli con alimentazione 'non definita' oppure 'altre' in una nuova categoria 'altro' ([Alimentazione]== 'Non Definito' || 'Altre' --> 'Altro')\n",
        "3. Rimuovo i record per i quali non è definita la regione ([REGIONE]== 'Non Definito' --> RIMUOVERE)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nnS1E1tYQS3"
      },
      "source": [
        "Stampa dei valori che saranno rimossi/aggregati/modificati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ISKJKDL2ufd"
      },
      "outputs": [],
      "source": [
        "#'REGIONE' == NON DEFINITO\n",
        "print (df_filt[df_filt['REGIONE']=='NON DEFINITO'].to_string())\n",
        "\n",
        "# Record con 'NON IDENTIFICATO' != 0\n",
        "print (df_filt[df_filt['Non identificato']!=0].to_string())\n",
        "\n",
        "#'ALIMENTAZIONE' == NON DEFINITO\n",
        "print (df_filt[df_filt['ALIMENTAZIONE']=='NON DEFINITO'].to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZVVfA2W883Zx"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "# Creo un df temporaneo in cui inserire i record da modificare\n",
        "df_tmp = df_filt[df_filt['Non identificato'] != 0]\n",
        "# Sommo i valori: Seleziono le sole righe relative agli indici di dt_tmp e la colonna 'EURO 0' su cui sommare\n",
        "df_filt.loc[df_tmp.index, 'EURO 0'] += df_tmp['Non identificato']\n",
        "#Rimuovo la colonna \"non identificato\"\n",
        "df_filt = df_filt.drop(columns=['Non identificato'])\n",
        "\n",
        "#print (df_filt.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc4nhEhoGPLH"
      },
      "outputs": [],
      "source": [
        "#2\n",
        "#CREO UN DATASET TEMPORANEO IN CUI INSERISCO LE NUOVE RIGHE (con ALIMENTAZIONE=ALTRO) il cui valore è dato dalla somma delle righe con alimentazione=ALTRE || NON DEFINITO\n",
        "df_tmp = df_filt[df_filt['ALIMENTAZIONE'].isin(['ALTRE','NON DEFINITO'])].groupby(['REGIONE','ANNO']).sum(numeric_only=True).reset_index()\n",
        "df_tmp.insert(loc=1,column='ALIMENTAZIONE',value='ALTRO')\n",
        "#RIMUOVO LE RIGHE DA DF DI PARTENZA DOVE ALIMENTAZIONE = ALTRE o = NON DEFINITO\n",
        "df_filt.drop(df_filt[df_filt['ALIMENTAZIONE'].isin(['ALTRE', 'NON DEFINITO'])].index, inplace=True)\n",
        "\n",
        "#3\n",
        "#RIMUOVO LE RIGHE DA DF DI PARTENZA DOVE REGIONE = 'NON DEFINITO\"\n",
        "df_filt.drop(df_filt[df_filt['REGIONE'] == 'NON DEFINITO'].index, inplace=True)\n",
        "\n",
        "#UNISCO IL TUTTO IN UN NUOVO DATAFRAME (Altrimenti una volta alterato questo blocco di codice non troverebbe piu oggetti da lavorare)\n",
        "df_wrk = pd.concat([df_filt,df_tmp],ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhYcagb9Qz5e"
      },
      "source": [
        "# PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMQSTffJp9ts"
      },
      "source": [
        "Partendo dalla tipologia di alimentazione, aggiungo il campo 'TIPOLOGIA-MOTORE' per rappresentare la classe di motorizzazione (ENDOTERMICO - ELETTRICO - IBRIBO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOJ0VZ5k8xyI"
      },
      "outputs": [],
      "source": [
        "# Valori distinti dei tipi di alimentazione\n",
        "print(df_wrk['ALIMENTAZIONE'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0DMQn1D1qCUx"
      },
      "outputs": [],
      "source": [
        "# Creo un dizionario per mappare la classe di motorizzazione del veicolo\n",
        "engine_map ={\n",
        "  'BENZINA': 'ENDOTERMICO',\n",
        "\t'BENZINA E GAS LIQUIDO': 'ENDOTERMICO',\n",
        "\t'BENZINA E METANO': 'ENDOTERMICO',\n",
        "\t'ELETTRICITA': 'ELETTRICO',\n",
        "\t'GASOLIO': 'ENDOTERMICO',\n",
        "\t'GASOLIO E GAS': 'ENDOTERMICO',\n",
        "\t'IBRIDO BENZINA': 'IBRIDO',\n",
        "\t'IBRIDO GASOLIO': 'IBRIDO',\n",
        "\t'METANO': 'ENDOTERMICO',\n",
        "\t'ELETTRICO-IBRIDO': 'ELETTRICO',\n",
        "\t'ALTRO': 'ENDOTERMICO'\n",
        "}\n",
        "\n",
        "#aggiungo la colonna al dataframe per la rappresentazione della variabile tipologia motore, in posizione 2 mettendo in join la colonna \"alimentazione\" con il dizionario sopra\n",
        "df_wrk.insert(2,'TIPOLOGIA_MOTORE',df_wrk['ALIMENTAZIONE'].map(engine_map).fillna('NON TROVATA'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hThr2fMHNPIG"
      },
      "source": [
        "Partendo dalla regione, aggiungo il campo 'AREA_GEOGRAFICA' (NORD-EST, NORD-OVEST,CENTRO,SUD,ISOLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9NLq-d5NTMW"
      },
      "outputs": [],
      "source": [
        "zone_map={\n",
        "  'ABRUZZO': 'SUD',\n",
        "  'BASILICATA': 'SUD',\n",
        "  'CALABRIA': 'SUD',\n",
        "  'CAMPANIA': 'SUD',\n",
        "  'EMILIA ROMAGNA': 'NORD-EST',\n",
        "  'FRIULI VENEZIA GIULIA': 'NORD-EST',\n",
        "  'LAZIO': 'CENTRO',\n",
        "  'LIGURIA': 'NORD-OVEST',\n",
        "  'LOMBARDIA': 'NORD-OVEST',\n",
        "  'MARCHE': 'CENTRO',\n",
        "  'MOLISE': 'SUD',\n",
        "  'PIEMONTE': 'NORD-OVEST',\n",
        "  'PUGLIA': 'SUD',\n",
        "  'SARDEGNA': 'ISOLE',\n",
        "  'SICILIA': 'ISOLE',\n",
        "  'TOSCANA': 'CENTRO',\n",
        "  'TRENTINO ALTO ADIGE': 'NORD-EST',\n",
        "  'UMBRIA': 'CENTRO',\n",
        "  'VALLE D\\'AOSTA': 'NORD-OVEST',\n",
        "  'VENETO': 'NORD-EST'\n",
        "}\n",
        "df_wrk.insert(0,'AREA_GEOGRAFICA',df_wrk['REGIONE'].map(zone_map).fillna('NON TROVATA'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kjD4V7Fy-Sv"
      },
      "source": [
        "Ottimizzo il dataframe finale secondo le esigenze della rappresentazione grafica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMEwwRMGy6Cg"
      },
      "outputs": [],
      "source": [
        "#Raggruppo per regione,tipologia ed anno sommando il totale veicoli (rimuovendo di conseguenza tutti i campi superflui)\n",
        "df_graph = df_wrk.groupby(['AREA_GEOGRAFICA','REGIONE','TIPOLOGIA_MOTORE','ANNO'])['TOTALE'].sum().reset_index()\n",
        "#Rimuovo la \"regione\" italia\n",
        "df_graph = df_graph[df_graph['REGIONE'] != 'ITALIA']\n",
        "\n",
        "#esporto in excel\n",
        "df_graph.to_excel(\"/content/circolante_powerbi.xlsx\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tj0tAI7HBtqn",
        "VhYcagb9Qz5e"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
